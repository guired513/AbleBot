
# AbleBot: NLP and Multimodal Toolchain Overview

## Purpose
This document outlines the finalized AI toolchain to be used in the development of the AbleBot system, focusing on accessibility for Persons with Disabilities (PWDs) through multimodal interactions â€” text, speech, and images.

## Core Components

| Component | Role in AbleBot | Tool / Framework |
|-----------|-----------------|------------------|
| Text Understanding (NLP) | Intent recognition, response generation | ğŸ¤– BERT via HuggingFace Transformers |
| Speech-to-Text (STT) | Voice command input from PWD users | ğŸ—£ï¸ Whisper by OpenAI |
| Text-to-Speech (TTS) | Speak responses for visually impaired users | ğŸ”Š Google Cloud TTS API |
| Optical Character Recognition (OCR) | Read signs, text documents, IDs from camera input | ğŸ‘ï¸ Tesseract OCR Engine |
| Fallback NLP Option | Backup chatbot using GPT-based generation | ğŸ’¬ OpenAI GPT API (Optional) |

## Tool Descriptions

### BERT
Platform: HuggingFace Transformers  
Use: Classify user intents (e.g., â€œApply for PhilHealth,â€ â€œWhere is the nearest hospital?â€)  
Customization: Fine-tuned on localized intents + Filipino/Bicol samples  
Output: Intent label â†’ triggers appropriate module

### Whisper (STT)
Platform: OpenAI Whisper (base or small model)  
Use: Converts user voice commands to text  
Advantage: High accuracy for Filipino-accented English and regional dialects  
Output: Transcribed text â†’ sent to BERT for intent classification

### Tesseract (OCR)
Platform: Tesseract OCR engine (open source)  
Use: Converts images (e.g., IDs, documents, signs) to machine-readable text  
Use case: Assist users in reading real-world text captured through the phone camera

### Google Cloud Text-to-Speech
Converts botâ€™s response into natural-sounding voice  
Useful for blind users or those with low literacy  
Languages: English, Filipino supported

### GPT-3.5 Turbo (Optional)
Used only in fallback conversations or open-ended interactions  
Rate-limited and controlled to reduce costs

## Integration Flow

```
[Voice Input] â”€â”€â–¶ Whisper STT â”€â”€â–¶ BERT â”€â”€â–¶ Response â”€â”€â–¶ Google TTS
     â”‚                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â–¶ OCR (if image) â”€â”€â”€â”€â”€â”€â”˜
```

## GitHub Repository Structure

```
/models
   â””â”€â”€ bert_intent_classifier
   â””â”€â”€ whisper_stt
   â””â”€â”€ ocr_reader
/api
   â””â”€â”€ chatbot_logic.py
   â””â”€â”€ audio_pipeline.py
/docs
   â””â”€â”€ toolchain_overview.md
   â””â”€â”€ usage_examples/
